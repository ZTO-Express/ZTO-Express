<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>中通技术团队</title>
  
  <subtitle>中通技术团队</subtitle>
  <link href="https://zto_express.gitee.io/atom.xml" rel="self"/>
  
  <link href="https://zto_express.gitee.io/"/>
  <updated>2020-08-15T02:51:23.408Z</updated>
  <id>https://zto_express.gitee.io/</id>
  
  <author>
    <name>[object Object]</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>中通Elasticsearch集群运维实践（二）--监控告警</title>
    <link href="https://zto_express.gitee.io/2020/08/15/es/"/>
    <id>https://zto_express.gitee.io/2020/08/15/es/</id>
    <published>2020-08-15T02:32:54.000Z</published>
    <updated>2020-08-15T02:51:23.408Z</updated>
    
    <content type="html"><![CDATA[<h4 id="背景介绍："><a href="#背景介绍：" class="headerlink" title="背景介绍："></a>背景介绍：</h4><p>中通在2015年的时候已经开始预研并在生产环境使用Elasticsearch集群，随后在科技中心开始大规模实践。随着业务的快速发展，es集群数量和规模也越来越大，版本的跨度也逐渐拉大，统一管理这些es集群逐渐变成了首要问题，在这种情况下，我们研发了中通ES运维监控平台–ESPaaS，提供了ES集群的自动化部署，统一监控，实时告警和索引管理等一系列运维管理功能，截止2020年7月底，中通生产上运行的es集群数量已经有40+个，节点数量500+个，单个集群的节点数从3个到100多个，单日新增文档数量近600亿，单日数据增量超过100tb，数据总量已经超6PB。</p><p>不同的阶段，关注和解决的问题也不一样，ESPaaS平台的版本迭代主要分为以下几个阶段：</p><img src="time-line.png" style="zoom： 50%；" /><p>本文主要介绍的是中通ESPaaS运维平台在统一监控告警上的实践，主要关注以下内容：</p><ol><li>集群实时监控</li><li>告警输出</li><li>集群诊断</li></ol><h4 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h4><p><code>prometheus</code>作为现在最流行的监控解决方案之一，经过一番调研，决定以<code>prometheus</code>为核心，搭建监控体系，监控告警的整体架构如下图所示：</p><img src="monitor.png" style="zoom： 50%；" /><p>整个监控模块围绕<code>prometheus</code>进行展开，主要的功能有：</p><ol><li>自研exporter获取线上es集群的关键指标信息，暴露的rest接口能根据请求中的集群名称返回不同集群的监控信息；</li><li>prometheus采取pull模式，定期请求exporter以获取es集群的监控信息；</li><li>grafana配置监控大盘对监控数据进行可视化；</li><li>告警应用给予promQL定期计算是否有指标异常，指标细化到各个es集群；</li><li>告警渠道目前主要采用钉钉，及时发送告警信息到钉钉群，快速定位问题集群、节点信息；</li><li>告警设立优先级，同时触发优先级高的先行发送，直指问题本质；</li><li>延迟告警避免偶发抖动造成的频繁告警与告警恢复；</li><li>诊断模块整合实时信息和历史监控趋势，发现潜在问题，消灭问题于萌芽状态；</li></ol><h4 id="集群监控与告警"><a href="#集群监控与告警" class="headerlink" title="集群监控与告警"></a>集群监控与告警</h4><p>为了保证ES集群的稳定运行，我们需要从多个维度对ES集群进行监控，主要的维度信息如下：</p><ul><li>资源类，包含部署ES机器的cpu、内存、网络、磁盘等信息；</li><li>集群级，ES集群本身是否处于健康状态，从一个较大的维度确认集群是否正常；</li><li>节点级，ES作为一个分布式的应用，每个节点的状态会最终影响集群的状态，需要对节点的jvm、线程池等进行监控；</li></ul><p>最终形成的监控大盘如下：</p><img src="monitor-1.png" style="zoom： 50%；" /><p>告警配置：</p><img src="warn-02.png" style="zoom：50%；" /><p>告警信息：</p><img src="warn-dingding.png"  /><h4 id="集群诊断"><a href="#集群诊断" class="headerlink" title="集群诊断"></a>集群诊断</h4><p>上面的监控告警能帮助我们快速定位集群的现有的问题，但是从长远角度来看，我们需要在问题出现之前提前发现、提前解决，尽可能避免生产故障。带着这样的思考，我们决定提供es集群的诊断能力–将对问题的排查手段和实践经验进行复用，将其标准化，最终沉淀在我们的集群诊断模块中。</p><p>诊断模块的设计思想是核心指标量化，利用量化的指标来帮助我们明确优化方向和快速定位问题，总结日常的问题排查和解决经验，我们将诊断分为五个维度：</p><img src="cluster-judge.png" style="zoom： 50%；" /><p>集群诊断基本涵盖了日常处理es集群问题的大部分场景，通过集群诊断，我们能够提前发现集群的潜在问题，通过提前扩容，更改索引设计与使用方式等行为来规避可能的生产问题。在集群监控和诊断的保驾护航下，2020年至今ESPaaS运维平台管理的ES集群没有发生生产故障。</p><p>诊断建议的界面：</p><img src="zhenduan.png" style="zoom： 50%；" /><h4 id="实践经验"><a href="#实践经验" class="headerlink" title="实践经验"></a>实践经验</h4><p>在监控告警和集群诊断的实际开发与使用过程中，我们也积累了很多的经验。</p><h5 id="1、es集群突然无法写入了，应用日志中全部都是写入失败的记录？"><a href="#1、es集群突然无法写入了，应用日志中全部都是写入失败的记录？" class="headerlink" title="1、es集群突然无法写入了，应用日志中全部都是写入失败的记录？"></a>1、es集群突然无法写入了，应用日志中全部都是写入失败的记录？</h5><p>在实际的问题排查中，发现大部分情况下都是集群部分节点磁盘超过90%触发当前节点的索引read_only，导致无法写入。</p><p>解决措施： </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 解除索引只读</span><br><span class="line">PUT _all/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;index.blocks.read_only_allow_delete&quot;</span>:<span class="string">&quot;false&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发生磁盘超过水位线的问题，一方面是对索引或者集群的容量规划做的不到位，另一方面也是监控告警的缺乏导致问题最终发生了。在引入监控告警后，我们对各个ES集群的磁盘设置了告警水位线，80%是告警的阈值，在集群的磁盘超标前，能够发送告警信息，让我们有时间和业务方提前沟通清理数据释放部分磁盘空间。在集群诊断中，我们依据磁盘过去一段时间的使用比例线性预测一天、七天后的使用量，提前和业务方进行沟通，对可能出现问题的集群提前进行扩容，避免出现资源瓶颈。</p><h5 id="2、监控大盘的信息解读"><a href="#2、监控大盘的信息解读" class="headerlink" title="2、监控大盘的信息解读"></a>2、监控大盘的信息解读</h5><p>监控大盘的引入，将监控指标以图表的形式展示出来，让我们能够直观的看到监控指标的当前数值和变化趋势，能帮助我们快速对es集群的资源利用率，性能瓶颈有一个大致的认知.通过下面的监控信息可以看出：</p><ol><li>集群当前是green状态，节点分布是 1master+13data节点；</li><li>主分片数量197，分片数量较少，不会出现单个节点数千个分片的情况；</li><li>多数节点节点在7:00-8:00gc较为频繁，此时段可能为业务高峰期，可能会有大量的写入或者查询等操作；</li><li>整体堆内存占用在50-70%之间，证明集群整体资源暂时没有瓶颈；</li><li>gc次数和gc耗时的面板发现有节点出现毛刺，可以通过分片监控查看是否分片分配不均匀导致了热节点；</li></ol><img src="monitor-2.png" style="zoom：50%；" /><h5 id="3、频繁告警的处理"><a href="#3、频繁告警的处理" class="headerlink" title="3、频繁告警的处理"></a>3、频繁告警的处理</h5><p>在告警功能初次上线时，有些集群的资源使用率比较高，部分节点内存占用超标了，当时的告警策略是一分钟检测一次，如果有异常就产生告警。这会带来频繁告警的问题，如果问题修复的时间较长，那每分钟都会产生一次告警信息，造成告警信息轰炸，告警群的告警信息全部都是同一条，不禁让人厌烦，还会导致开发小伙伴忽略其他的告警内容。</p><p>面对这种情况，参考一些业界的告警设计，在初次告警后，再次触发的告警不再立马发出，而是给予不同的时间间隔，如果在告警半小时后，问题没有解决，指标依旧异常，则产生第二次钉钉告警，告警间隔逐级顺延直至恢复，大大减少了重复的告警数量。</p><h5 id="4、延迟告警的设计"><a href="#4、延迟告警的设计" class="headerlink" title="4、延迟告警的设计"></a>4、延迟告警的设计</h5><p>内部的日志es集群，会存储近2月的日志索引，但是7天前的默认会关闭，由于经常有同学需要排查历史问题需要开启已经closed掉的索引，在索引开启的过程中，会造成日志es集群的短暂red/yellow状态，导致触发告警后又立即恢复，在钉钉告警群中大量刷消息。</p><p>面对这种能够自恢复的问题，我们决定设置延迟告警的策略，如果在告警触发的数分钟内(可配置)，告警指标恢复正常则不再进行告警，将这类偶发的抖动问题变成静默状态，不再干扰正常的告警。</p><h4 id="脚踏实地，展望未来"><a href="#脚踏实地，展望未来" class="headerlink" title="脚踏实地，展望未来"></a>脚踏实地，展望未来</h4><ol><li><p>ES容器化</p><blockquote><p>kubernetes的应用越来越广泛，ES+k8s将是中通在有状态服务上的探索与尝试；</p></blockquote></li><li><p>ES-Proxy–提供搜索服务</p><blockquote><p>未来希望将ES提供的搜索能力标准化，用户通过proxy使用ES，不必关心具体ES集群部署和索引分布；</p></blockquote></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;背景介绍：&quot;&gt;&lt;a href=&quot;#背景介绍：&quot; class=&quot;headerlink&quot; title=&quot;背景介绍：&quot;&gt;&lt;/a&gt;背景介绍：&lt;/h4&gt;&lt;p&gt;中通在2015年的时候已经开始预研并在生产环境使用Elasticsearch集群，随后在科技中心开始大规模实践。随着</summary>
      
    
    
    
    
    <category term="ES" scheme="https://zto_express.gitee.io/tags/ES/"/>
    
    <category term="搜索" scheme="https://zto_express.gitee.io/tags/%E6%90%9C%E7%B4%A2/"/>
    
    <category term="运维" scheme="https://zto_express.gitee.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="平台" scheme="https://zto_express.gitee.io/tags/%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="集群" scheme="https://zto_express.gitee.io/tags/%E9%9B%86%E7%BE%A4/"/>
    
    <category term="监控" scheme="https://zto_express.gitee.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>中通消息服务运维平台实践（已开源）</title>
    <link href="https://zto_express.gitee.io/2020/08/15/zms/"/>
    <id>https://zto_express.gitee.io/2020/08/15/zms/</id>
    <published>2020-08-14T16:28:50.000Z</published>
    <updated>2020-08-15T02:51:22.039Z</updated>
    
    <content type="html"><![CDATA[<p>中通快递每天有数千万的运单在各个环节运转，每个环节都有对应的多套业务系统来支撑，业务系统之间上下游关系较为密切，从上游的客户订单到下游转运、结算、分析等每个环节都离不开消息中间件，它主要解决了系统之前的耦合、业务的削峰填谷、异步通信、数据同步和冗余存储等等功能需求，是现有系统架构中，不同系统之间交互的主要方式之一。</p><p>在2015年中通开始大量采用消息中间解决一些特定的问题，随着业务的增长，各环节有了更精细化的产品，我们消息中间件的数据体量越来越大，集群规模越来越多，中间件也越来越多样化，统一管理这些消息中间件变得尤为重要，因此我们研发了中通消息中间件平台ZMS，主要基于RocketMQ+Kafka两套业界比较主流消息中间件，提供了自动化部署、主题/消费者的申请审核、统一的SDK、管理控制台、监控告警到无感知扩容迁移等一系列运维的功能，目前ZMS管理了17个集群，包括7个Kafka集群和10个RocketMQ集群，主题1000多个，消费组3000多个，日均消息流转达到百亿级。</p><p>ZMS从最初的版本演进到现在，基本围绕我们的最初设计的功能，根据每个阶段的痛点不同，解决不同的问题。整个过程，根据不同阶段的不同输出，大体可以三个维度。<br><img src="1.png" alt="1"></p><p>经公司内部评估，ZMS 已经成长为一套相对成熟的消息中间件云平台化解决方案，可以正式对外开放，与社会上的同行共同打磨，故决定于2020年5月26号正式开源，将代码推送到github 仓库，开源地址信息如下：</p><p>官方开源地址：<a href="https://gitee.com/zto_express/zms">https://gitee.com/zto_express/zms</a></p><h2 id="1、自动化运维与部署"><a href="#1、自动化运维与部署" class="headerlink" title="1、自动化运维与部署"></a>1、自动化运维与部署</h2><p>自动化运维部署，主要是方便运维人员可以快速通过ZMS平台向导式初始化一个集群，其架构设计如下图所示。</p><p><img src="2.png" alt="2"></p><p>zms-portal：zms 管理后台，可同时管理多个环境的资源，包括：添加主机、服务，消息集群状态监控、配置消息集群告警规则，消息集群资源管理等。</p><blockquote><p> 备注：所谓的环境我们可以简单看出开发环境、测试环境、高保真环境、生产环境。</p></blockquote><p>在每台机器上首先需要安装 zms-agent (代理服务)、supervisor 等基础组件，为了方便运维，ZMS 提供了一键初始化主机的脚本，其操作流程如下：</p><p><img src="3.png" alt="3"></p><p>运维人员只需要去指定的机器上复制上述命令即可。这样实现的目的是 zms-portal 无需管理宿主机器的用户名、密码等敏感信息，做到安全可控。zms 能自动感知安装了 zms-agent 的机器并将其纳入 zms-portal 的管理运维体系。</p><p>在 ZMS 中我们统一将 Kafka、RocketMQ、ZK、指标收集、监控告警等统一看成是一个服务，在不同的环境中可以选择性的安装，其操作如下图所示：</p><p><img src="4.png" alt="4"></p><h2 id="2、统一的客户端-SDK"><a href="#2、统一的客户端-SDK" class="headerlink" title="2、统一的客户端 SDK"></a>2、统一的客户端 SDK</h2><p>基于中通业务的特点在具体项目中采用了Kafka与RocketMQ 两种不同的消息中间件，如果业务方在自己项目中既要使用 Kafka 的消息中间件，又要使用 RocketMQ 的消息中间件，对于消息中间件的使用来说要求非常高，因为需要了解这些相似又不同的 API，分别了解其配置参数与其代表的含义，因此为业务方提供统一的API显得尤为重要与迫切。</p><p>zms-sdk 的主要设计理念：</p><ul><li>屏蔽底层消息中间件类型，提供统一标准的API。</li><li>提供标准的埋点，方便打造完备的监控体系。</li><li>云平台化，开发人员只需关注TOPIC、消费组本身，无需关注 TOPIC 是存储在哪个集群上，即将 TOPIC、消费组资源化，用户只需按需向平台申请 topic、消费组即可。</li></ul><p>zms-sdk 的整体架构设计如图所示：</p><p><img src="5.png" alt="5"></p><p>主要的交互与设计要点如下：</p><ul><li>运维人员通过 zms-portal 在线安装集群，集群的元数据将会存在 zookeeper 中。</li><li>开发人员通过在 zms-portal 申请 topic、消费组。</li><li>运维人员在 zms-portal 中对用户的申请进行审批，并根据用户的需求分配到适合的集群中，topic 所在集群等元信息会写入到 zookeeper中。</li><li>开发人员通过 zms-sdk 向所申请的 topic 发送消息，zms-sdk 内部会从 zk 获取 topic 对应的元信息并创建对应的客户端，最终完成消息的发送。</li></ul><p>整个设计的核心是引入 zookeeper 作为元数据的存储仓库，并充分利用其事件监听机制，能完成很多“高大上”的功能，例如主题在线迁移功能。</p><p>试想一下在双十一等大促场景，如果一个集群负载很高从而达到瓶颈，一方面是可以对集群进行扩容，另外一种可行的方法时将该集群中的 topic 迁移到其他空间集群，正是依托于 zookeeper 的事件机制，应用客户端无需重启就可以自动感知 topic 的配置发生了变化，从而重新构建到新集群的客户端对象，完成消息发送的不停机在线迁移。</p><h2 id="3、监控数据采集服务"><a href="#3、监控数据采集服务" class="headerlink" title="3、监控数据采集服务"></a>3、监控数据采集服务</h2><p>对消息中间件进行监控并进行可视化展示是运维最基本的需求，RocketMQ、Kafka 消息中间件本身提供了监控数据的采集并存储在各自的服务端内存，并且是非持久化的，在内存中只存储当前时间段的调用信息，并随着时间的推进，旧的数据将被删除。当然 RocketMQ、Kafka 都提供了相应的API方便客户端采集存储在服务端内存中的监控数据。</p><p>ZMSCollector 的职责就是定时向 RocketMQ、Kafka 集群采集相关的调用信息并持久化到 influxdb中，为后续的可视化展示提供必要的基础，ZMSCollector 已经被服务化，可以通过 zms-portal 在线安装。</p><p>ZMSCollector 的整体架构设计如下图所示：</p><p><img src="6.png" alt="6"></p><p>ZMSCollector 的整体设计比较简单，一方面通过定时调度的方式调用底层消息中间件提供的API，将监控指标存储到 influxDb，另外一方面采集 zms-sdk 采集的监控数据，zms-sdk采集的监控数据会发送的一个固定的 topic ，ZMSCollector 订阅指定的 topic，对消息进行加工后存储在 influxDb中。</p><h2 id="4、多机房解决方案"><a href="#4、多机房解决方案" class="headerlink" title="4、多机房解决方案"></a>4、多机房解决方案</h2><p>目前中通在异地容灾方面还刚刚起步，目前只需要实现同城机房冷备，即一个机房的入口网络发生故障，需要将流量切换到另外一个备份机房。ZMS 消息中间件运维平台天然支持多机房的部署架构，因为在 ZMS 的“眼中”，一个不同的机房就相当于一个环境，可以直接在 zms-portal 中完成一个新机房的安装部署服务。但由于发生故障后，两个机房内部的网络有可能会断开，故两个机房中的元数据应该分开存储，即 zms-sdk 所依懒的 zookeeper 集群不同，故需要完成 zookeeper 元数据的同步，该工作由 ZMSBackupCluster 服务来承担，其架构设计如下图所示：</p><p><img src="7.png" alt="7"></p><p>其基本的设计思路是 ZMSBackupCluster 订阅待同步机房的 zookeeper，一旦元数据有发生变化，会按照配置集群元数据映射关系将其同步到目标机房的 zookeeper中，这样部署在备份机房中的应用可以无感知的接管主机房中所有的消息发送与消息消费任务。</p><h2 id="5、zms-portal-部分界面展示"><a href="#5、zms-portal-部分界面展示" class="headerlink" title="5、zms-portal 部分界面展示"></a>5、zms-portal 部分界面展示</h2><p>zms-portal 提供了集群自动化安装部署、主题消费组审批、各种监控报表可视化报表，接下来展示部分界面，详细请移步 zms 开源仓库。</p><p><img src="8.png" alt="8"></p><p><img src="9.png" alt="9"></p><p><img src="10.png" alt="10"></p><p><img src="11.png" alt="11"></p><p><img src="12.png" alt="12"></p><p><img src="13.png" alt="13"></p><p><img src="14.png" alt="14"></p><h2 id="6、ZMS-开源信息"><a href="#6、ZMS-开源信息" class="headerlink" title="6、ZMS 开源信息"></a>6、ZMS 开源信息</h2><p>中通科技正式开源内部的消息Pass云平台化产品ZMS，其开源仓库地址： github ，包含了 ZMS 的使用说明、架构设计文档、技术交流群。开源只是完成万里长征第一步，后续希望更多的开源爱好者加入到该项目中，共同打造一体化的智能消息运维平台。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;中通快递每天有数千万的运单在各个环节运转，每个环节都有对应的多套业务系统来支撑，业务系统之间上下游关系较为密切，从上游的客户订单到下游转运、结算、分析等每个环节都离不开消息中间件，它主要解决了系统之前的耦合、业务的削峰填谷、异步通信、数据同步和冗余存储等等功能需求，是现有系</summary>
      
    
    
    
    
    <category term="中通" scheme="https://zto_express.gitee.io/tags/%E4%B8%AD%E9%80%9A/"/>
    
    <category term="消息" scheme="https://zto_express.gitee.io/tags/%E6%B6%88%E6%81%AF/"/>
    
    <category term="MQ" scheme="https://zto_express.gitee.io/tags/MQ/"/>
    
    <category term="RocketMQ" scheme="https://zto_express.gitee.io/tags/RocketMQ/"/>
    
    <category term="Kafka" scheme="https://zto_express.gitee.io/tags/Kafka/"/>
    
  </entry>
  
</feed>
